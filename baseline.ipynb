{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d52db436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5897c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28d3f714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>polarization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en_973938b90b0ff5d87d35a582f83f5c89</td>\n",
       "      <td>is defending imperialism in the dnd chat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en_07dfd4600426caca6e2c5883fcbea9ea</td>\n",
       "      <td>Still playing with this. I am now following Ra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en_f14519ff2302b6cd47712073f13bc461</td>\n",
       "      <td>.senate.gov Theres 3 groups out there Republic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en_e48b7e7542faafa544ac57b64bc80daf</td>\n",
       "      <td>\"ABC MD, David Anderson, said the additional f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en_7c581fb77bce8033aeba3d6dbd6273eb</td>\n",
       "      <td>\"bad people\" I have some conservative values s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  \\\n",
       "0  en_973938b90b0ff5d87d35a582f83f5c89   \n",
       "1  en_07dfd4600426caca6e2c5883fcbea9ea   \n",
       "2  en_f14519ff2302b6cd47712073f13bc461   \n",
       "3  en_e48b7e7542faafa544ac57b64bc80daf   \n",
       "4  en_7c581fb77bce8033aeba3d6dbd6273eb   \n",
       "\n",
       "                                                text  polarization  \n",
       "0           is defending imperialism in the dnd chat             0  \n",
       "1  Still playing with this. I am now following Ra...             0  \n",
       "2  .senate.gov Theres 3 groups out there Republic...             0  \n",
       "3  \"ABC MD, David Anderson, said the additional f...             0  \n",
       "4  \"bad people\" I have some conservative values s...             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('subtask1/train/eng.csv')\n",
    "val = pd.read_csv('subtask1/dev/eng.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06462d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train['text']\n",
    "train_labels = train['polarization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f05f42c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1674, 1: 1002})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af57c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_random(train_labels, num_samples):\n",
    "    predictions = []\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    proportion = len(train_labels[train_labels == 1]) / len(train_labels)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        if random.random() < proportion:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "\n",
    "    return np.array(predictions, dtype=int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36830d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_random(train_labels, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b783612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    tokens = text.lower().split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5357ea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted_labels, true_labels):\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "    true_labels = np.array(true_labels)\n",
    "    correct = np.sum(predicted_labels == true_labels)\n",
    "    return correct / len(true_labels)\n",
    "\n",
    "def precision(predicted_labels, true_labels):\n",
    "    \n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "    true_labels = np.array(true_labels)\n",
    "\n",
    "    true_pos = np.sum((predicted_labels == 1) & (true_labels == 1))\n",
    "    pred_pos = np.sum(predicted_labels == 1)\n",
    "\n",
    "    precision_value = true_pos / (pred_pos)\n",
    "    return precision_value\n",
    "\n",
    "\n",
    "def recall(predicted_labels, true_labels):\n",
    "\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "    true_labels = np.array(true_labels)\n",
    "\n",
    "    true_pos = np.sum((predicted_labels == 1) & (true_labels == 1))\n",
    "    actual_pos = np.sum(true_labels == 1)\n",
    "\n",
    "    recall_value = true_pos / (actual_pos)\n",
    "    return recall_value\n",
    "\n",
    "def f1_score(predicted_labels, true_labels):\n",
    "\n",
    "    precision_value = precision(predicted_labels, true_labels)\n",
    "    recall_value = recall(predicted_labels, true_labels)\n",
    "\n",
    "    f1_score_value = 2 * (precision_value * recall_value) / (precision_value + recall_value)\n",
    "    return f1_score_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5d26878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e84488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bd2afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = vectorizer.fit_transform(eval_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "963e010a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2676, 5000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea086134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(coefficients):\n",
    "    with torch.no_grad():\n",
    "        coefficients.weight.fill_(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f71f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self, input_dim: int):\n",
    "        super().__init__()\n",
    "        self.output_size = 1\n",
    "        self.coefficients = torch.nn.Linear(input_dim, self.output_size)\n",
    "        initialize_weights(self.coefficients)\n",
    "        \n",
    "    def forward(self, features: torch.Tensor):\n",
    "        return torch.sigmoid(self.coefficients(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5da286a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_loss(prediction: torch.Tensor, label: torch.Tensor) -> torch.Tensor:\n",
    "    eps = 1e-18\n",
    "    loss = -1 * (\n",
    "        label * torch.log(prediction + eps) + \n",
    "        (1 - label) * torch.log(1 - prediction + eps)\n",
    "    )\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bb730d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(model, learning_rate) -> torch.optim:\n",
    "    return torch.optim.SGD(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdc7342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, features):\n",
    "    with torch.no_grad():\n",
    "        logits = model(features)\n",
    "\n",
    "        predicted_labels = (logits > 0.5).int().flatten()\n",
    "\n",
    "        return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e2d980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb255744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(\n",
    "    num_epochs,\n",
    "    batch_size,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    dev_features,\n",
    "    dev_labels,\n",
    "    optimizer,\n",
    "    model\n",
    "):\n",
    "    samples = list(zip(train_features, train_labels))\n",
    "    random.shuffle(samples)\n",
    "    batches = []\n",
    "    for i in range(0, len(samples), batch_size):\n",
    "        batches.append(samples[i:i+batch_size])\n",
    "    print(\"Training...\")\n",
    "    train_losses = []\n",
    "    dev_losses = []\n",
    "    for i in range(num_epochs):\n",
    "        for batch in tqdm(batches):\n",
    "            # Empty the dynamic computation graph\n",
    "            features, labels = zip(*batch)\n",
    "            features = torch.stack(features)\n",
    "            print(\"FEATURES: \", features)\n",
    "            labels = torch.stack(labels)\n",
    "            optimizer.zero_grad()\n",
    "            # Run the model\n",
    "            logits = model(features)\n",
    "            print(logits)\n",
    "            # Compute loss\n",
    "            loss = logistic_loss(torch.squeeze(logits), labels)\n",
    "            print(\"Loss: \", loss)\n",
    "            # In this logistic regression example,\n",
    "            # this entails computing a single gradient\n",
    "            loss.backward()\n",
    "            # Backpropogate the loss through our model\n",
    "            \n",
    "            # Update our coefficients in the direction of the gradient.\n",
    "            optimizer.step()\n",
    "             # For logging\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            # Compute dev loss for our reference\n",
    "            dev_logits = model(dev_features)\n",
    "            dev_loss = logistic_loss(torch.squeeze(dev_logits), dev_labels)\n",
    "            dev_losses.append(dev_loss.item())\n",
    "        \n",
    "        # Estimate the f1 score for the development set\n",
    "        dev_f1 = f1_score(predict(model, dev_features), dev_labels.tolist())\n",
    "        print(f\"epoch {i}\")\n",
    "        print(f\"Train loss: {sum(train_losses)/len(train_losses)}\")\n",
    "        print(f\"Dev loss: {sum(dev_losses)/len(dev_losses)}\")\n",
    "        print(f\"Dev F1 {dev_f1}\")\n",
    "        \n",
    "    # Return the trained model\n",
    "    return model, train_losses, dev_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf3d217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "lr = 1e-3\n",
    "model = Classifier(X.shape[1])\n",
    "optimizer = make_optimizer(model, learning_rate = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2029b373",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not csr_matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dev_logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Classes/Fall '25/NLP - Martin/Assignments/SemEval2026-task9/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Classes/Fall '25/NLP - Martin/Assignments/SemEval2026-task9/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mClassifier.forward\u001b[39m\u001b[34m(self, features)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: torch.Tensor):\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# We predict a number by multipling by the coefficients\u001b[39;00m\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# and then take the sigmoid to turn the score as logits\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.sigmoid(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcoefficients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Classes/Fall '25/NLP - Martin/Assignments/SemEval2026-task9/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Classes/Fall '25/NLP - Martin/Assignments/SemEval2026-task9/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Classes/Fall '25/NLP - Martin/Assignments/SemEval2026-task9/.venv/lib/python3.13/site-packages/torch/nn/modules/linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: linear(): argument 'input' (position 1) must be Tensor, not csr_matrix"
     ]
    }
   ],
   "source": [
    "dev_logits = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04ae382",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model, train_losses, dev_losses = training_loop(\n",
    "    num_epochs,\n",
    "    16,\n",
    "    X,\n",
    "    train_labels,\n",
    "    dev_features,\n",
    "    dev_labels,\n",
    "    optimizer,\n",
    "    model\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
